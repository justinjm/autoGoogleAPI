% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/automl_objects.R
\name{OutputConfig}
\alias{OutputConfig}
\title{OutputConfig Object}
\usage{
OutputConfig(bigqueryDestination = NULL, gcsDestination = NULL)
}
\arguments{
\item{bigqueryDestination}{The BigQuery location where the output is to be written to}

\item{gcsDestination}{The Google Cloud Storage location where the output is to be written to}
}
\value{
OutputConfig object
}
\description{
OutputConfig Object
}
\details{
Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
Output configuration for ExportData.As destination thegcs_destinationmust be set unless specified otherwise for a domain.Only ground truth annotations are exported (not approved annotations arenot exported).The outputs correspond to how the data was imported, and may be used asinput to import data. The output formats are represented as EBNF with literalcommas and same non-terminal symbols definitions are these in import data'sInputConfig: *  For Image Object Detection:        CSV file(s) `image_object_detection_1.csv`,        `image_object_detection_2.csv`,...,`image_object_detection_N.csv`        with each line in format:        ML_USE,GCS_FILE_PATH,[LABEL],(BOUNDING_BOX | ,,,,,,,)        where GCS_FILE_PATHs point at the original, source locations of the        imported images. *  For Video Classification:        CSV file `video_classification.csv`, with each line in format:        ML_USE,GCS_FILE_PATH        (may have muliple lines per a single ML_USE).        Each GCS_FILE_PATH leads to another .csv file which        describes examples that have given ML_USE, using the following        row format:        GCS_FILE_PATH,LABEL,TIME_SEGMENT_START,TIME_SEGMENT_END        Here GCS_FILE_PATHs point at the original, source locations of the        imported videos. *  For Text Extraction:        CSV file `text_extraction.csv`, with each line in format:        ML_USE,GCS_FILE_PATH        GCS_FILE_PATH leads to a .JSONL (i.e. JSON Lines) file which        contains, per line, a proto that wraps a TextSnippet proto (in json        representation) followed by AnnotationPayload protos (called        annotations). If initially documents had been imported, the JSONL        will point at the original, source locations of the imported        documents. *  For Text Sentiment:        CSV file `text_sentiment.csv`, with each line in format:        ML_USE,GCS_FILE_PATH,SENTIMENT        where GCS_FILE_PATH points at a txt file which contains thecontent        of the example.  *  For Tables:        Output depends on whether the dataset was imported from GCS or        BigQuery.        GCS case:gcs_destination          must be set. Exported are CSV file(s) `tables_1.csv`,          `tables_2.csv`,...,`tables_N.csv` with each having as header line          the table's column names, and all other lines contain values for          the header columns.        BigQuery case:bigquery_destination          pointing to a BigQuery project must be set. In the given project a          new dataset will be created with name`export_data_<automl-dataset-display-name>_<timestamp-of-export-call>`          where <automl-dataset-display-name> will be made          BigQuery-dataset-name compatible (e.g. most special characters will          become underscores), and timestamp will be in          YYYY_MM_DDThh_mm_ss_sssZ 'based on ISO-8601' format. In that          dataset a new table called `primary_table` will be created, and          filled with precisely the same data as this obtained on import.
}
\concept{OutputConfig functions}
