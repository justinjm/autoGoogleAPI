#' Cloud AutoML API Objects 
#' Train high-quality custom machine learning models with minimum effort and machine learning expertise.
#' 
#' Auto-generated code by googleAuthR::gar_create_api_objects
#'  at 2021-04-16 10:03:03
#' filename: /Users/justin/dev/R/autoGoogleAPI/googleautomlv1.auto/R/automl_objects.R
#' api_json: api_json
#' 
#' Objects for use by the functions created by googleAuthR::gar_create_api_skeleton

#' TextExtractionAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Annotation for identifying spans of text.
#' 
#' @param score Output only
#' @param textSegment An entity annotation will set this, which is the part of the original text to which the annotation pertains
#' 
#' @return TextExtractionAnnotation object
#' 
#' @family TextExtractionAnnotation functions
#' @export
TextExtractionAnnotation <- function(score = NULL, textSegment = NULL) {
    structure(list(score = score, textSegment = textSegment), class = "gar_TextExtractionAnnotation")
}

#' ImageClassificationDatasetMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Dataset metadata that is specific to image classification.
#' 
#' @param classificationType Required
#' 
#' @return ImageClassificationDatasetMetadata object
#' 
#' @family ImageClassificationDatasetMetadata functions
#' @export
ImageClassificationDatasetMetadata <- function(classificationType = NULL) {
    structure(list(classificationType = classificationType), class = "gar_ImageClassificationDatasetMetadata")
}

#' TranslationDatasetMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Dataset metadata that is specific to translation.
#' 
#' @param sourceLanguageCode Required
#' @param targetLanguageCode Required
#' 
#' @return TranslationDatasetMetadata object
#' 
#' @family TranslationDatasetMetadata functions
#' @export
TranslationDatasetMetadata <- function(sourceLanguageCode = NULL, targetLanguageCode = NULL) {
    structure(list(sourceLanguageCode = sourceLanguageCode, targetLanguageCode = targetLanguageCode), 
        class = "gar_TranslationDatasetMetadata")
}

#' TextSentimentModelMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model metadata that is specific to text sentiment.
#' 
#' 
#' 
#' @return TextSentimentModelMetadata object
#' 
#' @family TextSentimentModelMetadata functions
#' @export
TextSentimentModelMetadata <- function() {
    list()
}

#' BatchPredictOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of BatchPredict operation.
#' 
#' @param inputConfig Output only
#' @param outputInfo Output only
#' 
#' @return BatchPredictOperationMetadata object
#' 
#' @family BatchPredictOperationMetadata functions
#' @export
BatchPredictOperationMetadata <- function(inputConfig = NULL, outputInfo = NULL) {
    structure(list(inputConfig = inputConfig, outputInfo = outputInfo), class = "gar_BatchPredictOperationMetadata")
}

#' BoundingBoxMetricsEntryConfidenceMetricsEntry Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metrics for a single confidence threshold.
#' 
#' @param precision Output only
#' @param confidenceThreshold Output only
#' @param f1Score Output only
#' @param recall Output only
#' 
#' @return BoundingBoxMetricsEntryConfidenceMetricsEntry object
#' 
#' @family BoundingBoxMetricsEntryConfidenceMetricsEntry functions
#' @export
BoundingBoxMetricsEntryConfidenceMetricsEntry <- function(precision = NULL, confidenceThreshold = NULL, 
    f1Score = NULL, recall = NULL) {
    structure(list(precision = precision, confidenceThreshold = confidenceThreshold, 
        f1Score = f1Score, recall = recall), class = "gar_BoundingBoxMetricsEntryConfidenceMetricsEntry")
}

#' ImageObjectDetectionAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Annotation details for image object detection.
#' 
#' @param boundingBox Output only
#' @param score Output only
#' 
#' @return ImageObjectDetectionAnnotation object
#' 
#' @family ImageObjectDetectionAnnotation functions
#' @export
ImageObjectDetectionAnnotation <- function(boundingBox = NULL, score = NULL) {
    structure(list(boundingBox = boundingBox, score = score), class = "gar_ImageObjectDetectionAnnotation")
}

#' ListModelsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Response message for AutoMl.ListModels.
#' 
#' @param nextPageToken A token to retrieve next page of results
#' @param model List of models in the requested page
#' 
#' @return ListModelsResponse object
#' 
#' @family ListModelsResponse functions
#' @export
ListModelsResponse <- function(nextPageToken = NULL, model = NULL) {
    structure(list(nextPageToken = nextPageToken, model = model), class = "gar_ListModelsResponse")
}

#' Status Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).
#' 
#' @param details A list of messages that carry the error details
#' @param message A developer-facing error message, which should be in English
#' @param code The status code, which should be an enum value of google
#' 
#' @return Status object
#' 
#' @family Status functions
#' @export
Status <- function(details = NULL, message = NULL, code = NULL) {
    structure(list(details = details, message = message, code = code), class = "gar_Status")
}

#' ClassificationEvaluationMetricsConfidenceMetricsEntry Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metrics for a single confidence threshold.
#' 
#' @param falsePositiveCount Output only
#' @param recall Output only
#' @param f1Score Output only
#' @param recallAt1 Output only
#' @param falsePositiveRateAt1 Output only
#' @param f1ScoreAt1 Output only
#' @param falseNegativeCount Output only
#' @param falsePositiveRate Output only
#' @param positionThreshold Output only
#' @param truePositiveCount Output only
#' @param trueNegativeCount Output only
#' @param confidenceThreshold Output only
#' @param precisionAt1 Output only
#' @param precision Output only
#' 
#' @return ClassificationEvaluationMetricsConfidenceMetricsEntry object
#' 
#' @family ClassificationEvaluationMetricsConfidenceMetricsEntry functions
#' @export
ClassificationEvaluationMetricsConfidenceMetricsEntry <- function(falsePositiveCount = NULL, 
    recall = NULL, f1Score = NULL, recallAt1 = NULL, falsePositiveRateAt1 = NULL, 
    f1ScoreAt1 = NULL, falseNegativeCount = NULL, falsePositiveRate = NULL, positionThreshold = NULL, 
    truePositiveCount = NULL, trueNegativeCount = NULL, confidenceThreshold = NULL, 
    precisionAt1 = NULL, precision = NULL) {
    structure(list(falsePositiveCount = falsePositiveCount, recall = recall, f1Score = f1Score, 
        recallAt1 = recallAt1, falsePositiveRateAt1 = falsePositiveRateAt1, f1ScoreAt1 = f1ScoreAt1, 
        falseNegativeCount = falseNegativeCount, falsePositiveRate = falsePositiveRate, 
        positionThreshold = positionThreshold, truePositiveCount = truePositiveCount, 
        trueNegativeCount = trueNegativeCount, confidenceThreshold = confidenceThreshold, 
        precisionAt1 = precisionAt1, precision = precision), class = "gar_ClassificationEvaluationMetricsConfidenceMetricsEntry")
}

#' GcsDestination Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The Google Cloud Storage location where the output is to be written to.
#' 
#' @param outputUriPrefix Required
#' 
#' @return GcsDestination object
#' 
#' @family GcsDestination functions
#' @export
GcsDestination <- function(outputUriPrefix = NULL) {
    structure(list(outputUriPrefix = outputUriPrefix), class = "gar_GcsDestination")
}

#' TextExtractionEvaluationMetricsConfidenceMetricsEntry Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metrics for a single confidence threshold.
#' 
#' @param precision Output only
#' @param confidenceThreshold Output only
#' @param recall Output only
#' @param f1Score Output only
#' 
#' @return TextExtractionEvaluationMetricsConfidenceMetricsEntry object
#' 
#' @family TextExtractionEvaluationMetricsConfidenceMetricsEntry functions
#' @export
TextExtractionEvaluationMetricsConfidenceMetricsEntry <- function(precision = NULL, 
    confidenceThreshold = NULL, recall = NULL, f1Score = NULL) {
    structure(list(precision = precision, confidenceThreshold = confidenceThreshold, 
        recall = recall, f1Score = f1Score), class = "gar_TextExtractionEvaluationMetricsConfidenceMetricsEntry")
}

#' ImageObjectDetectionModelMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model metadata specific to image object detection.
#' 
#' @param modelType Optional
#' @param trainBudgetMilliNodeHours Optional
#' 
#' @return ImageObjectDetectionModelMetadata object
#' 
#' @family ImageObjectDetectionModelMetadata functions
#' @export
ImageObjectDetectionModelMetadata <- function(modelType = NULL, trainBudgetMilliNodeHours = NULL) {
    structure(list(modelType = modelType, trainBudgetMilliNodeHours = trainBudgetMilliNodeHours), 
        class = "gar_ImageObjectDetectionModelMetadata")
}

#' ImageObjectDetectionEvaluationMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model evaluation metrics for image object detection problems. Evaluates prediction quality of labeled bounding boxes.
#' 
#' @param evaluatedBoundingBoxCount Output only
#' @param boundingBoxMeanAveragePrecision Output only
#' @param boundingBoxMetricsEntries Output only
#' 
#' @return ImageObjectDetectionEvaluationMetrics object
#' 
#' @family ImageObjectDetectionEvaluationMetrics functions
#' @export
ImageObjectDetectionEvaluationMetrics <- function(evaluatedBoundingBoxCount = NULL, 
    boundingBoxMeanAveragePrecision = NULL, boundingBoxMetricsEntries = NULL) {
    structure(list(evaluatedBoundingBoxCount = evaluatedBoundingBoxCount, boundingBoxMeanAveragePrecision = boundingBoxMeanAveragePrecision, 
        boundingBoxMetricsEntries = boundingBoxMetricsEntries), class = "gar_ImageObjectDetectionEvaluationMetrics")
}

#' Binding Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Associates `members` with a `role`.
#' 
#' @param condition The condition that is associated with this binding
#' @param role Role that is assigned to `members`
#' @param members Specifies the identities requesting access for a Cloud Platform resource
#' 
#' @return Binding object
#' 
#' @family Binding functions
#' @export
Binding <- function(condition = NULL, role = NULL, members = NULL) {
    structure(list(condition = condition, role = role, members = members), class = "gar_Binding")
}

#' ListModelEvaluationsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Response message for AutoMl.ListModelEvaluations.
#' 
#' @param modelEvaluation List of model evaluations in the requested page
#' @param nextPageToken A token to retrieve next page of results
#' 
#' @return ListModelEvaluationsResponse object
#' 
#' @family ListModelEvaluationsResponse functions
#' @export
ListModelEvaluationsResponse <- function(modelEvaluation = NULL, nextPageToken = NULL) {
    structure(list(modelEvaluation = modelEvaluation, nextPageToken = nextPageToken), 
        class = "gar_ListModelEvaluationsResponse")
}

#' TranslationModelMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model metadata that is specific to translation.
#' 
#' @param baseModel The resource name of the model to use as a baseline to train the custom model
#' @param sourceLanguageCode Output only
#' @param targetLanguageCode Output only
#' 
#' @return TranslationModelMetadata object
#' 
#' @family TranslationModelMetadata functions
#' @export
TranslationModelMetadata <- function(baseModel = NULL, sourceLanguageCode = NULL, 
    targetLanguageCode = NULL) {
    structure(list(baseModel = baseModel, sourceLanguageCode = sourceLanguageCode, 
        targetLanguageCode = targetLanguageCode), class = "gar_TranslationModelMetadata")
}

#' TextSentimentDatasetMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Dataset metadata for text sentiment.
#' 
#' @param sentimentMax Required
#' 
#' @return TextSentimentDatasetMetadata object
#' 
#' @family TextSentimentDatasetMetadata functions
#' @export
TextSentimentDatasetMetadata <- function(sentimentMax = NULL) {
    structure(list(sentimentMax = sentimentMax), class = "gar_TextSentimentDatasetMetadata")
}

#' ExportDataRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for AutoMl.ExportData.
#' 
#' @param outputConfig Required
#' 
#' @return ExportDataRequest object
#' 
#' @family ExportDataRequest functions
#' @export
ExportDataRequest <- function(outputConfig = NULL) {
    structure(list(outputConfig = outputConfig), class = "gar_ExportDataRequest")
}

#' TranslationEvaluationMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Evaluation metrics for the dataset.
#' 
#' @param baseBleuScore Output only
#' @param bleuScore Output only
#' 
#' @return TranslationEvaluationMetrics object
#' 
#' @family TranslationEvaluationMetrics functions
#' @export
TranslationEvaluationMetrics <- function(baseBleuScore = NULL, bleuScore = NULL) {
    structure(list(baseBleuScore = baseBleuScore, bleuScore = bleuScore), class = "gar_TranslationEvaluationMetrics")
}

#' TextSnippet Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A representation of a text snippet.
#' 
#' @param content Required
#' @param contentUri Output only
#' @param mimeType Optional
#' 
#' @return TextSnippet object
#' 
#' @family TextSnippet functions
#' @export
TextSnippet <- function(content = NULL, contentUri = NULL, mimeType = NULL) {
    structure(list(content = content, contentUri = contentUri, mimeType = mimeType), 
        class = "gar_TextSnippet")
}

#' Policy Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' An Identity and Access Management (IAM) policy, which specifies access controls for Google Cloud resources. A `Policy` is a collection of `bindings`. A `binding` binds one or more `members` to a single `role`. Members can be user accounts, service accounts, Google groups, and domains (such as G Suite). A `role` is a named list of permissions; each `role` can be an IAM predefined role or a user-created custom role. For some types of Google Cloud resources, a `binding` can also specify a `condition`, which is a logical expression that allows access to a resource only if the expression evaluates to `true`. A condition can add constraints based on attributes of the request, the resource, or both. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies). **JSON example:** { 'bindings': [ { 'role': 'roles/resourcemanager.organizationAdmin', 'members': [ 'user:mike@example.com', 'group:admins@example.com', 'domain:google.com', 'serviceAccount:my-project-id@appspot.gserviceaccount.com' ] }, { 'role': 'roles/resourcemanager.organizationViewer', 'members': [ 'user:eve@example.com' ], 'condition': { 'title': 'expirable access', 'description': 'Does not grant access after Sep 2020', 'expression': 'request.time < timestamp('2020-10-01T00:00:00.000Z')', } } ], 'etag': 'BwWWja0YfJA=', 'version': 3 } **YAML example:** bindings: - members: - user:mike@example.com - group:admins@example.com - domain:google.com - serviceAccount:my-project-id@appspot.gserviceaccount.com role: roles/resourcemanager.organizationAdmin - members: - user:eve@example.com role: roles/resourcemanager.organizationViewer condition: title: expirable access description: Does not grant access after Sep 2020 expression: request.time < timestamp('2020-10-01T00:00:00.000Z') - etag: BwWWja0YfJA= - version: 3 For a description of IAM and its features, see the [IAM documentation](https://cloud.google.com/iam/docs/).
#' 
#' @param etag `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other
#' @param bindings Associates a list of `members` to a `role`
#' @param version Specifies the format of the policy
#' 
#' @return Policy object
#' 
#' @family Policy functions
#' @export
Policy <- function(etag = NULL, bindings = NULL, version = NULL) {
    structure(list(etag = etag, bindings = bindings, version = version), class = "gar_Policy")
}

#' NormalizedVertex Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A vertex represents a 2D point in the image. The normalized vertex coordinates are between 0 to 1 fractions relative to the original plane (image, video). E.g. if the plane (e.g. whole image) would have size 10 x 20 then a point with normalized coordinates (0.1, 0.3) would be at the position (1, 6) on that plane.
#' 
#' @param y Required
#' @param x Required
#' 
#' @return NormalizedVertex object
#' 
#' @family NormalizedVertex functions
#' @export
NormalizedVertex <- function(y = NULL, x = NULL) {
    structure(list(y = y, x = x), class = "gar_NormalizedVertex")
}

#' CreateDatasetOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of CreateDataset operation.
#' 
#' 
#' 
#' @return CreateDatasetOperationMetadata object
#' 
#' @family CreateDatasetOperationMetadata functions
#' @export
CreateDatasetOperationMetadata <- function() {
    list()
}

#' DeployModelOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of DeployModel operation.
#' 
#' 
#' 
#' @return DeployModelOperationMetadata object
#' 
#' @family DeployModelOperationMetadata functions
#' @export
DeployModelOperationMetadata <- function() {
    list()
}

#' Layout Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Describes the layout information of a text_segment in the document.
#' 
#' @param textSegmentType The type of the text_segment in document
#' @param pageNumber Page number of the text_segment in the original document, starts from 1
#' @param textSegment Text Segment that represents a segment in document_text
#' @param boundingPoly The position of the text_segment in the page
#' 
#' @return Layout object
#' 
#' @family Layout functions
#' @export
Layout <- function(textSegmentType = NULL, pageNumber = NULL, textSegment = NULL, 
    boundingPoly = NULL) {
    structure(list(textSegmentType = textSegmentType, pageNumber = pageNumber, textSegment = textSegment, 
        boundingPoly = boundingPoly), class = "gar_Layout")
}

#' Operation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' This resource represents a long-running operation that is the result of a network API call.
#' 
#' @param Operation.response The \link{Operation.response} object or list of objects
#' @param Operation.metadata The \link{Operation.metadata} object or list of objects
#' @param name The server-assigned name, which is only unique within the same service that originally returns it
#' @param done If the value is `false`, it means the operation is still in progress
#' @param error The error result of the operation in case of failure or cancellation
#' @param response The normal response of the operation in case of success
#' @param metadata Service-specific metadata associated with the operation
#' 
#' @return Operation object
#' 
#' @family Operation functions
#' @export
Operation <- function(Operation.response = NULL, Operation.metadata = NULL, name = NULL, 
    done = NULL, error = NULL, response = NULL, metadata = NULL) {
    structure(list(Operation.response = Operation.response, Operation.metadata = Operation.metadata, 
        name = name, done = done, error = error, response = response, metadata = metadata), 
        class = "gar_Operation")
}

#' Operation.response Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
#' 
#' 
#' 
#' @return Operation.response object
#' 
#' @family Operation functions
#' @export
Operation.response <- function() {
    list()
}

#' Operation.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
#' 
#' 
#' 
#' @return Operation.metadata object
#' 
#' @family Operation functions
#' @export
Operation.metadata <- function() {
    list()
}

#' TranslationAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Annotation details specific to translation.
#' 
#' @param translatedContent Output only 
#' 
#' @return TranslationAnnotation object
#' 
#' @family TranslationAnnotation functions
#' @export
TranslationAnnotation <- function(translatedContent = NULL) {
    structure(list(translatedContent = translatedContent), class = "gar_TranslationAnnotation")
}

#' ExportModelOutputInfo Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Further describes the output of model export. Supplements ModelExportOutputConfig.
#' 
#' @param gcsOutputDirectory The full path of the Google Cloud Storage directory created, into which the model will be exported
#' 
#' @return ExportModelOutputInfo object
#' 
#' @family ExportModelOutputInfo functions
#' @export
ExportModelOutputInfo <- function(gcsOutputDirectory = NULL) {
    structure(list(gcsOutputDirectory = gcsOutputDirectory), class = "gar_ExportModelOutputInfo")
}

#' ImageObjectDetectionDatasetMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Dataset metadata specific to image object detection.
#' 
#' 
#' 
#' @return ImageObjectDetectionDatasetMetadata object
#' 
#' @family ImageObjectDetectionDatasetMetadata functions
#' @export
ImageObjectDetectionDatasetMetadata <- function() {
    list()
}

#' TestIamPermissionsRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for `TestIamPermissions` method.
#' 
#' @param permissions The set of permissions to check for the `resource`
#' 
#' @return TestIamPermissionsRequest object
#' 
#' @family TestIamPermissionsRequest functions
#' @export
TestIamPermissionsRequest <- function(permissions = NULL) {
    structure(list(permissions = permissions), class = "gar_TestIamPermissionsRequest")
}

#' TextExtractionEvaluationMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model evaluation metrics for text extraction problems.
#' 
#' @param confidenceMetricsEntries Output only
#' @param auPrc Output only
#' 
#' @return TextExtractionEvaluationMetrics object
#' 
#' @family TextExtractionEvaluationMetrics functions
#' @export
TextExtractionEvaluationMetrics <- function(confidenceMetricsEntries = NULL, auPrc = NULL) {
    structure(list(confidenceMetricsEntries = confidenceMetricsEntries, auPrc = auPrc), 
        class = "gar_TextExtractionEvaluationMetrics")
}

#' TextExtractionDatasetMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Dataset metadata that is specific to text extraction
#' 
#' 
#' 
#' @return TextExtractionDatasetMetadata object
#' 
#' @family TextExtractionDatasetMetadata functions
#' @export
TextExtractionDatasetMetadata <- function() {
    list()
}

#' BoundingPoly Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A bounding polygon of a detected object on a plane. On output both vertices and normalized_vertices are provided. The polygon is formed by connecting vertices in the order they are listed.
#' 
#' @param normalizedVertices Output only 
#' 
#' @return BoundingPoly object
#' 
#' @family BoundingPoly functions
#' @export
BoundingPoly <- function(normalizedVertices = NULL) {
    structure(list(normalizedVertices = normalizedVertices), class = "gar_BoundingPoly")
}

#' ExportModelOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of ExportModel operation.
#' 
#' @param outputInfo Output only
#' 
#' @return ExportModelOperationMetadata object
#' 
#' @family ExportModelOperationMetadata functions
#' @export
ExportModelOperationMetadata <- function(outputInfo = NULL) {
    structure(list(outputInfo = outputInfo), class = "gar_ExportModelOperationMetadata")
}

#' BatchPredictOutputConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Output configuration for BatchPredict Action. As destination the gcs_destination must be set unless specified otherwise for a domain. If gcs_destination is set then in the given directory a new directory is created. Its name will be 'prediction--', where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. The contents of it depends on the ML problem the predictions are made for. * For Image Classification: In the created directory files `image_classification_1.jsonl`, `image_classification_2.jsonl`,...,`image_classification_N.jsonl` will be created, where N may be 1, and depends on the total number of the successfully predicted images and annotations. A single image will be listed only once with all its annotations, and its annotations will never be split across files. Each .JSONL file will contain, per line, a JSON representation of a proto that wraps image's 'ID' : '' followed by a list of zero or more AnnotationPayload protos (called annotations), which have classification detail populated. If prediction for any image failed (partially or completely), then an additional `errors_1.jsonl`, `errors_2.jsonl`,..., `errors_N.jsonl` files will be created (N depends on total number of failed predictions). These files will have a JSON representation of a proto that wraps the same 'ID' : '' but here followed by exactly one [`google.rpc.Status`](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto) containing only `code` and `message`fields. * For Image Object Detection: In the created directory files `image_object_detection_1.jsonl`, `image_object_detection_2.jsonl`,...,`image_object_detection_N.jsonl` will be created, where N may be 1, and depends on the total number of the successfully predicted images and annotations. Each .JSONL file will contain, per line, a JSON representation of a proto that wraps image's 'ID' : '' followed by a list of zero or more AnnotationPayload protos (called annotations), which have image_object_detection detail populated. A single image will be listed only once with all its annotations, and its annotations will never be split across files. If prediction for any image failed (partially or completely), then additional `errors_1.jsonl`, `errors_2.jsonl`,..., `errors_N.jsonl` files will be created (N depends on total number of failed predictions). These files will have a JSON representation of a proto that wraps the same 'ID' : '' but here followed by exactly one [`google.rpc.Status`](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto) containing only `code` and `message`fields. * For Video Classification: In the created directory a video_classification.csv file, and a .JSON file per each video classification requested in the input (i.e. each line in given CSV(s)), will be created. The format of video_classification.csv is: GCS_FILE_PATH,TIME_SEGMENT_START,TIME_SEGMENT_END,JSON_FILE_NAME,STATUS where: GCS_FILE_PATH,TIME_SEGMENT_START,TIME_SEGMENT_END = matches 1 to 1 the prediction input lines (i.e. video_classification.csv has precisely the same number of lines as the prediction input had.) JSON_FILE_NAME = Name of .JSON file in the output directory, which contains prediction responses for the video time segment. STATUS = 'OK' if prediction completed successfully, or an error code with message otherwise. If STATUS is not 'OK' then the .JSON file for that line may not exist or be empty. Each .JSON file, assuming STATUS is 'OK', will contain a list of AnnotationPayload protos in JSON format, which are the predictions for the video time segment the file is assigned to in the video_classification.csv. All AnnotationPayload protos will have video_classification field set, and will be sorted by video_classification.type field (note that the returned types are governed by `classifaction_types` parameter in PredictService.BatchPredictRequest.params). * For Video Object Tracking: In the created directory a video_object_tracking.csv file will be created, and multiple files video_object_trackinng_1.json, video_object_trackinng_2.json,..., video_object_trackinng_N.json, where N is the number of requests in the input (i.e. the number of lines in given CSV(s)). The format of video_object_tracking.csv is: GCS_FILE_PATH,TIME_SEGMENT_START,TIME_SEGMENT_END,JSON_FILE_NAME,STATUS where: GCS_FILE_PATH,TIME_SEGMENT_START,TIME_SEGMENT_END = matches 1 to 1 the prediction input lines (i.e. video_object_tracking.csv has precisely the same number of lines as the prediction input had.) JSON_FILE_NAME = Name of .JSON file in the output directory, which contains prediction responses for the video time segment. STATUS = 'OK' if prediction completed successfully, or an error code with message otherwise. If STATUS is not 'OK' then the .JSON file for that line may not exist or be empty. Each .JSON file, assuming STATUS is 'OK', will contain a list of AnnotationPayload protos in JSON format, which are the predictions for each frame of the video time segment the file is assigned to in video_object_tracking.csv. All AnnotationPayload protos will have video_object_tracking field set. * For Text Classification: In the created directory files `text_classification_1.jsonl`, `text_classification_2.jsonl`,...,`text_classification_N.jsonl` will be created, where N may be 1, and depends on the total number of inputs and annotations found. Each .JSONL file will contain, per line, a JSON representation of a proto that wraps input text file (or document) in the text snippet (or document) proto and a list of zero or more AnnotationPayload protos (called annotations), which have classification detail populated. A single text file (or document) will be listed only once with all its annotations, and its annotations will never be split across files. If prediction for any input file (or document) failed (partially or completely), then additional `errors_1.jsonl`, `errors_2.jsonl`,..., `errors_N.jsonl` files will be created (N depends on total number of failed predictions). These files will have a JSON representation of a proto that wraps input file followed by exactly one [`google.rpc.Status`](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto) containing only `code` and `message`. * For Text Sentiment: In the created directory files `text_sentiment_1.jsonl`, `text_sentiment_2.jsonl`,...,`text_sentiment_N.jsonl` will be created, where N may be 1, and depends on the total number of inputs and annotations found. Each .JSONL file will contain, per line, a JSON representation of a proto that wraps input text file (or document) in the text snippet (or document) proto and a list of zero or more AnnotationPayload protos (called annotations), which have text_sentiment detail populated. A single text file (or document) will be listed only once with all its annotations, and its annotations will never be split across files. If prediction for any input file (or document) failed (partially or completely), then additional `errors_1.jsonl`, `errors_2.jsonl`,..., `errors_N.jsonl` files will be created (N depends on total number of failed predictions). These files will have a JSON representation of a proto that wraps input file followed by exactly one [`google.rpc.Status`](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto) containing only `code` and `message`. * For Text Extraction: In the created directory files `text_extraction_1.jsonl`, `text_extraction_2.jsonl`,...,`text_extraction_N.jsonl` will be created, where N may be 1, and depends on the total number of inputs and annotations found. The contents of these .JSONL file(s) depend on whether the input used inline text, or documents. If input was inline, then each .JSONL file will contain, per line, a JSON representation of a proto that wraps given in request text snippet's 'id' (if specified), followed by input text snippet, and a list of zero or more AnnotationPayload protos (called annotations), which have text_extraction detail populated. A single text snippet will be listed only once with all its annotations, and its annotations will never be split across files. If input used documents, then each .JSONL file will contain, per line, a JSON representation of a proto that wraps given in request document proto, followed by its OCR-ed representation in the form of a text snippet, finally followed by a list of zero or more AnnotationPayload protos (called annotations), which have text_extraction detail populated and refer, via their indices, to the OCR-ed text snippet. A single document (and its text snippet) will be listed only once with all its annotations, and its annotations will never be split across files. If prediction for any text snippet failed (partially or completely), then additional `errors_1.jsonl`, `errors_2.jsonl`,..., `errors_N.jsonl` files will be created (N depends on total number of failed predictions). These files will have a JSON representation of a proto that wraps either the 'id' : '' (in case of inline) or the document proto (in case of document) but here followed by exactly one [`google.rpc.Status`](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto) containing only `code` and `message`. * For Tables: Output depends on whether gcs_destination or bigquery_destination is set (either is allowed). Google Cloud Storage case: In the created directory files `tables_1.csv`, `tables_2.csv`,..., `tables_N.csv` will be created, where N may be 1, and depends on the total number of the successfully predicted rows. For all CLASSIFICATION prediction_type-s: Each .csv file will contain a header, listing all columns' display_name-s given on input followed by M target column names in the format of '__score' where M is the number of distinct target values, i.e. number of distinct values in the target column of the table used to train the model. Subsequent lines will contain the respective values of successfully predicted rows, with the last, i.e. the target, columns having the corresponding prediction scores. For REGRESSION and FORECASTING prediction_type-s: Each .csv file will contain a header, listing all columns' display_name-s given on input followed by the predicted target column with name in the format of 'predicted_' Subsequent lines will contain the respective values of successfully predicted rows, with the last, i.e. the target, column having the predicted target value. If prediction for any rows failed, then an additional `errors_1.csv`, `errors_2.csv`,..., `errors_N.csv` will be created (N depends on total number of failed rows). These files will have analogous format as `tables_*.csv`, but always with a single target column having [`google.rpc.Status`](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto) represented as a JSON string, and containing only `code` and `message`. BigQuery case: bigquery_destination pointing to a BigQuery project must be set. In the given project a new dataset will be created with name `prediction__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores), and timestamp will be in YYYY_MM_DDThh_mm_ss_sssZ 'based on ISO-8601' format. In the dataset two tables will be created, `predictions`, and `errors`. The `predictions` table's column names will be the input columns' display_name-s followed by the target column with name in the format of 'predicted_' The input feature columns will contain the respective values of successfully predicted rows, with the target column having an ARRAY of AnnotationPayloads, represented as STRUCT-s, containing TablesAnnotation. The `errors` table contains rows for which the prediction has failed, it has analogous input columns while the target column name is in the format of 'errors_', and as a value has [`google.rpc.Status`](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto) represented as a STRUCT, and containing only `code` and `message`.
#' 
#' @param gcsDestination Required
#' 
#' @return BatchPredictOutputConfig object
#' 
#' @family BatchPredictOutputConfig functions
#' @export
BatchPredictOutputConfig <- function(gcsDestination = NULL) {
    structure(list(gcsDestination = gcsDestination), class = "gar_BatchPredictOutputConfig")
}

#' TextExtractionModelMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model metadata that is specific to text extraction.
#' 
#' 
#' 
#' @return TextExtractionModelMetadata object
#' 
#' @family TextExtractionModelMetadata functions
#' @export
TextExtractionModelMetadata <- function() {
    list()
}

#' BatchPredictOutputInfo Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Further describes this batch predict's output. Supplements BatchPredictOutputConfig.
#' 
#' @param gcsOutputDirectory The full path of the Google Cloud Storage directory created, into which the prediction output is written
#' 
#' @return BatchPredictOutputInfo object
#' 
#' @family BatchPredictOutputInfo functions
#' @export
BatchPredictOutputInfo <- function(gcsOutputDirectory = NULL) {
    structure(list(gcsOutputDirectory = gcsOutputDirectory), class = "gar_BatchPredictOutputInfo")
}

#' TestIamPermissionsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Response message for `TestIamPermissions` method.
#' 
#' @param permissions A subset of `TestPermissionsRequest
#' 
#' @return TestIamPermissionsResponse object
#' 
#' @family TestIamPermissionsResponse functions
#' @export
TestIamPermissionsResponse <- function(permissions = NULL) {
    structure(list(permissions = permissions), class = "gar_TestIamPermissionsResponse")
}

#' ExportDataOutputInfo Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Further describes this export data's output. Supplements OutputConfig.
#' 
#' @param gcsOutputDirectory The full path of the Google Cloud Storage directory created, into which the exported data is written
#' 
#' @return ExportDataOutputInfo object
#' 
#' @family ExportDataOutputInfo functions
#' @export
ExportDataOutputInfo <- function(gcsOutputDirectory = NULL) {
    structure(list(gcsOutputDirectory = gcsOutputDirectory), class = "gar_ExportDataOutputInfo")
}

#' GcsSource Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The Google Cloud Storage location for the input content.
#' 
#' @param inputUris Required
#' 
#' @return GcsSource object
#' 
#' @family GcsSource functions
#' @export
GcsSource <- function(inputUris = NULL) {
    structure(list(inputUris = inputUris), class = "gar_GcsSource")
}

#' SetIamPolicyRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for `SetIamPolicy` method.
#' 
#' @param policy REQUIRED: The complete policy to be applied to the `resource`
#' 
#' @return SetIamPolicyRequest object
#' 
#' @family SetIamPolicyRequest functions
#' @export
SetIamPolicyRequest <- function(policy = NULL) {
    structure(list(policy = policy), class = "gar_SetIamPolicyRequest")
}

#' Image Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A representation of an image. Only images up to 30MB in size are supported.
#' 
#' @param imageBytes Image content represented as a stream of bytes
#' @param thumbnailUri Output only
#' 
#' @return Image object
#' 
#' @family Image functions
#' @export
Image <- function(imageBytes = NULL, thumbnailUri = NULL) {
    structure(list(imageBytes = imageBytes, thumbnailUri = thumbnailUri), class = "gar_Image")
}

#' CancelOperationRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The request message for Operations.CancelOperation.
#' 
#' 
#' 
#' @return CancelOperationRequest object
#' 
#' @family CancelOperationRequest functions
#' @export
CancelOperationRequest <- function() {
    list()
}

#' ModelExportOutputConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Output configuration for ModelExport Action.
#' 
#' @param ModelExportOutputConfig.params The \link{ModelExportOutputConfig.params} object or list of objects
#' @param params Additional model-type and format specific parameters describing the requirements for the to be exported model files, any string must be up to 25000 characters long
#' @param gcsDestination Required
#' @param modelFormat The format in which the model must be exported
#' 
#' @return ModelExportOutputConfig object
#' 
#' @family ModelExportOutputConfig functions
#' @export
ModelExportOutputConfig <- function(ModelExportOutputConfig.params = NULL, params = NULL, 
    gcsDestination = NULL, modelFormat = NULL) {
    structure(list(ModelExportOutputConfig.params = ModelExportOutputConfig.params, 
        params = params, gcsDestination = gcsDestination, modelFormat = modelFormat), 
        class = "gar_ModelExportOutputConfig")
}

#' ModelExportOutputConfig.params Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Additional model-type and format specific parameters describing the requirements for the to be exported model files, any string must be up to 25000 characters long. * For `docker` format: `cpu_architecture` - (string) 'x86_64' (default). `gpu_architecture` - (string) 'none' (default), 'nvidia'.
#' 
#' 
#' 
#' @return ModelExportOutputConfig.params object
#' 
#' @family ModelExportOutputConfig functions
#' @export
ModelExportOutputConfig.params <- function() {
    list()
}

#' DocumentDimensions Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Message that describes dimension of a document.
#' 
#' @param height Height value of the document, works together with the unit
#' @param unit Unit of the dimension
#' @param width Width value of the document, works together with the unit
#' 
#' @return DocumentDimensions object
#' 
#' @family DocumentDimensions functions
#' @export
DocumentDimensions <- function(height = NULL, unit = NULL, width = NULL) {
    structure(list(height = height, unit = unit, width = width), class = "gar_DocumentDimensions")
}

#' UndeployModelRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for AutoMl.UndeployModel.
#' 
#' 
#' 
#' @return UndeployModelRequest object
#' 
#' @family UndeployModelRequest functions
#' @export
UndeployModelRequest <- function() {
    list()
}

#' UndeployModelOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of UndeployModel operation.
#' 
#' 
#' 
#' @return UndeployModelOperationMetadata object
#' 
#' @family UndeployModelOperationMetadata functions
#' @export
UndeployModelOperationMetadata <- function() {
    list()
}

#' PredictResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Response message for PredictionService.Predict.
#' 
#' @param PredictResponse.metadata The \link{PredictResponse.metadata} object or list of objects
#' @param payload Prediction result
#' @param preprocessedInput The preprocessed example that AutoML actually makes prediction on
#' @param metadata Additional domain-specific prediction response metadata
#' 
#' @return PredictResponse object
#' 
#' @family PredictResponse functions
#' @export
PredictResponse <- function(PredictResponse.metadata = NULL, payload = NULL, preprocessedInput = NULL, 
    metadata = NULL) {
    structure(list(PredictResponse.metadata = PredictResponse.metadata, payload = payload, 
        preprocessedInput = preprocessedInput, metadata = metadata), class = "gar_PredictResponse")
}

#' PredictResponse.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Additional domain-specific prediction response metadata. AutoML Vision Object Detection `max_bounding_box_count` : (int64) The maximum number of bounding boxes to return per image. AutoML Natural Language Sentiment Analysis `sentiment_score` : (float, deprecated) A value between -1 and 1, -1 maps to least positive sentiment, while 1 maps to the most positive one and the higher the score, the more positive the sentiment in the document is. Yet these values are relative to the training data, so e.g. if all data was positive then -1 is also positive (though the least). `sentiment_score` is not the same as 'score' and 'magnitude' from Sentiment Analysis in the Natural Language API.
#' 
#' 
#' 
#' @return PredictResponse.metadata object
#' 
#' @family PredictResponse functions
#' @export
PredictResponse.metadata <- function() {
    list()
}

#' ImportDataOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of ImportData operation.
#' 
#' 
#' 
#' @return ImportDataOperationMetadata object
#' 
#' @family ImportDataOperationMetadata functions
#' @export
ImportDataOperationMetadata <- function() {
    list()
}

#' WaitOperationRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The request message for Operations.WaitOperation.
#' 
#' @param timeout The maximum duration to wait before timing out
#' 
#' @return WaitOperationRequest object
#' 
#' @family WaitOperationRequest functions
#' @export
WaitOperationRequest <- function(timeout = NULL) {
    structure(list(timeout = timeout), class = "gar_WaitOperationRequest")
}

#' ModelEvaluation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Evaluation results of a model.
#' 
#' @param classificationEvaluationMetrics Model evaluation metrics for image, text, video and tables classification
#' @param displayName Output only
#' @param imageObjectDetectionEvaluationMetrics Model evaluation metrics for image object detection
#' @param textExtractionEvaluationMetrics Evaluation metrics for text extraction models
#' @param translationEvaluationMetrics Model evaluation metrics for translation
#' @param textSentimentEvaluationMetrics Evaluation metrics for text sentiment models
#' @param name Output only
#' @param evaluatedExampleCount Output only
#' @param annotationSpecId Output only
#' @param createTime Output only
#' 
#' @return ModelEvaluation object
#' 
#' @family ModelEvaluation functions
#' @export
ModelEvaluation <- function(classificationEvaluationMetrics = NULL, displayName = NULL, 
    imageObjectDetectionEvaluationMetrics = NULL, textExtractionEvaluationMetrics = NULL, 
    translationEvaluationMetrics = NULL, textSentimentEvaluationMetrics = NULL, name = NULL, 
    evaluatedExampleCount = NULL, annotationSpecId = NULL, createTime = NULL) {
    structure(list(classificationEvaluationMetrics = classificationEvaluationMetrics, 
        displayName = displayName, imageObjectDetectionEvaluationMetrics = imageObjectDetectionEvaluationMetrics, 
        textExtractionEvaluationMetrics = textExtractionEvaluationMetrics, translationEvaluationMetrics = translationEvaluationMetrics, 
        textSentimentEvaluationMetrics = textSentimentEvaluationMetrics, name = name, 
        evaluatedExampleCount = evaluatedExampleCount, annotationSpecId = annotationSpecId, 
        createTime = createTime), class = "gar_ModelEvaluation")
}

#' BatchPredictInputConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Input configuration for BatchPredict Action. The format of input depends on the ML problem of the model used for prediction. As input source the gcs_source is expected, unless specified otherwise. The formats are represented in EBNF with commas being literal and with non-terminal symbols defined near the end of this comment. The formats are: AutoML Vision Classification One or more CSV files where each line is a single column: GCS_FILE_PATH The Google Cloud Storage location of an image of up to 30MB in size. Supported extensions: .JPEG, .GIF, .PNG. This path is treated as the ID in the batch predict output. Sample rows: gs://folder/image1.jpeg gs://folder/image2.gif gs://folder/image3.png Object Detection One or more CSV files where each line is a single column: GCS_FILE_PATH The Google Cloud Storage location of an image of up to 30MB in size. Supported extensions: .JPEG, .GIF, .PNG. This path is treated as the ID in the batch predict output. Sample rows: gs://folder/image1.jpeg gs://folder/image2.gif gs://folder/image3.png AutoML Video Intelligence Classification One or more CSV files where each line is a single column: GCS_FILE_PATH,TIME_SEGMENT_START,TIME_SEGMENT_END `GCS_FILE_PATH` is the Google Cloud Storage location of video up to 50GB in size and up to 3h in duration duration. Supported extensions: .MOV, .MPEG4, .MP4, .AVI. `TIME_SEGMENT_START` and `TIME_SEGMENT_END` must be within the length of the video, and the end time must be after the start time. Sample rows: gs://folder/video1.mp4,10,40 gs://folder/video1.mp4,20,60 gs://folder/vid2.mov,0,inf Object Tracking One or more CSV files where each line is a single column: GCS_FILE_PATH,TIME_SEGMENT_START,TIME_SEGMENT_END `GCS_FILE_PATH` is the Google Cloud Storage location of video up to 50GB in size and up to 3h in duration duration. Supported extensions: .MOV, .MPEG4, .MP4, .AVI. `TIME_SEGMENT_START` and `TIME_SEGMENT_END` must be within the length of the video, and the end time must be after the start time. Sample rows: gs://folder/video1.mp4,10,40 gs://folder/video1.mp4,20,60 gs://folder/vid2.mov,0,inf AutoML Natural Language Classification One or more CSV files where each line is a single column: GCS_FILE_PATH `GCS_FILE_PATH` is the Google Cloud Storage location of a text file. Supported file extensions: .TXT, .PDF, .TIF, .TIFF Text files can be no larger than 10MB in size. Sample rows: gs://folder/text1.txt gs://folder/text2.pdf gs://folder/text3.tif Sentiment Analysis One or more CSV files where each line is a single column: GCS_FILE_PATH `GCS_FILE_PATH` is the Google Cloud Storage location of a text file. Supported file extensions: .TXT, .PDF, .TIF, .TIFF Text files can be no larger than 128kB in size. Sample rows: gs://folder/text1.txt gs://folder/text2.pdf gs://folder/text3.tif Entity Extraction One or more JSONL (JSON Lines) files that either provide inline text or documents. You can only use one format, either inline text or documents, for a single call to [AutoMl.BatchPredict]. Each JSONL file contains a per line a proto that wraps a temporary user-assigned TextSnippet ID (string up to 2000 characters long) called 'id', a TextSnippet proto (in JSON representation) and zero or more TextFeature protos. Any given text snippet content must have 30,000 characters or less, and also be UTF-8 NFC encoded (ASCII already is). The IDs provided should be unique. Each document JSONL file contains, per line, a proto that wraps a Document proto with `input_config` set. Each document cannot exceed 2MB in size. Supported document extensions: .PDF, .TIF, .TIFF Each JSONL file must not exceed 100MB in size, and no more than 20 JSONL files may be passed. Sample inline JSONL file (Shown with artificial line breaks. Actual line breaks are denoted by '\n'.): { 'id': 'my_first_id', 'text_snippet': { 'content': 'dog car cat'}, 'text_features': [ { 'text_segment': {'start_offset': 4, 'end_offset': 6}, 'structural_type': PARAGRAPH, 'bounding_poly': { 'normalized_vertices': [ {'x': 0.1, 'y': 0.1}, {'x': 0.1, 'y': 0.3}, {'x': 0.3, 'y': 0.3}, {'x': 0.3, 'y': 0.1}, ] }, } ], }\n { 'id': '2', 'text_snippet': { 'content': 'Extended sample content', 'mime_type': 'text/plain' } } Sample document JSONL file (Shown with artificial line breaks. Actual line breaks are denoted by '\n'.): { 'document': { 'input_config': { 'gcs_source': { 'input_uris': [ 'gs://folder/document1.pdf' ] } } } }\n { 'document': { 'input_config': { 'gcs_source': { 'input_uris': [ 'gs://folder/document2.tif' ] } } } } AutoML Tables See [Preparing your training data](https://cloud.google.com/automl-tables/docs/predict-batch) for more information. You can use either gcs_source or bigquery_source. **For gcs_source:** CSV file(s), each by itself 10GB or smaller and total size must be 100GB or smaller, where first file must have a header containing column names. If the first row of a subsequent file is the same as the header, then it is also treated as a header. All other rows contain values for the corresponding columns. The column names must contain the model's input_feature_column_specs' display_name-s (order doesn't matter). The columns corresponding to the model's input feature column specs must contain values compatible with the column spec's data types. Prediction on all the rows, i.e. the CSV lines, will be attempted. Sample rows from a CSV file: 'First Name','Last Name','Dob','Addresses' 'John','Doe','1968-01-22','[{'status':'current','address':'123_First_Avenue','city':'Seattle','state':'WA','zip':'11111','numberOfYears':'1'},{'status':'previous','address':'456_Main_Street','city':'Portland','state':'OR','zip':'22222','numberOfYears':'5'}]' 'Jane','Doe','1980-10-16','[{'status':'current','address':'789_Any_Avenue','city':'Albany','state':'NY','zip':'33333','numberOfYears':'2'},{'status':'previous','address':'321_Main_Street','city':'Hoboken','state':'NJ','zip':'44444','numberOfYears':'3'}]} **For bigquery_source:** The URI of a BigQuery table. The user data size of the BigQuery table must be 100GB or smaller. The column names must contain the model's input_feature_column_specs' display_name-s (order doesn't matter). The columns corresponding to the model's input feature column specs must contain values compatible with the column spec's data types. Prediction on all the rows of the table will be attempted. **Input field definitions:** `GCS_FILE_PATH` : The path to a file on Google Cloud Storage. For example, 'gs://folder/video.avi'. `TIME_SEGMENT_START` : (`TIME_OFFSET`) Expresses a beginning, inclusive, of a time segment within an example that has a time dimension (e.g. video). `TIME_SEGMENT_END` : (`TIME_OFFSET`) Expresses an end, exclusive, of a time segment within n example that has a time dimension (e.g. video). `TIME_OFFSET` : A number of seconds as measured from the start of an example (e.g. video). Fractions are allowed, up to a microsecond precision. 'inf' is allowed, and it means the end of the example. **Errors:** If any of the provided CSV files can't be parsed or if more than certain percent of CSV rows cannot be processed then the operation fails and prediction does not happen. Regardless of overall success or failure the per-row failures, up to a certain count cap, will be listed in Operation.metadata.partial_failures.
#' 
#' @param gcsSource Required
#' 
#' @return BatchPredictInputConfig object
#' 
#' @family BatchPredictInputConfig functions
#' @export
BatchPredictInputConfig <- function(gcsSource = NULL) {
    structure(list(gcsSource = gcsSource), class = "gar_BatchPredictInputConfig")
}

#' ClassificationEvaluationMetricsConfusionMatrixRow Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Output only. A row in the confusion matrix.
#' 
#' @param exampleCount Output only
#' 
#' @return ClassificationEvaluationMetricsConfusionMatrixRow object
#' 
#' @family ClassificationEvaluationMetricsConfusionMatrixRow functions
#' @export
ClassificationEvaluationMetricsConfusionMatrixRow <- function(exampleCount = NULL) {
    structure(list(exampleCount = exampleCount), class = "gar_ClassificationEvaluationMetricsConfusionMatrixRow")
}

#' TextClassificationDatasetMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Dataset metadata for classification.
#' 
#' @param classificationType Required
#' 
#' @return TextClassificationDatasetMetadata object
#' 
#' @family TextClassificationDatasetMetadata functions
#' @export
TextClassificationDatasetMetadata <- function(classificationType = NULL) {
    structure(list(classificationType = classificationType), class = "gar_TextClassificationDatasetMetadata")
}

#' ImageClassificationModelMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model metadata for image classification.
#' 
#' @param baseModelId Optional
#' @param trainBudgetMilliNodeHours Optional
#' @param modelType Optional
#' 
#' @return ImageClassificationModelMetadata object
#' 
#' @family ImageClassificationModelMetadata functions
#' @export
ImageClassificationModelMetadata <- function(baseModelId = NULL, trainBudgetMilliNodeHours = NULL, 
    modelType = NULL) {
    structure(list(baseModelId = baseModelId, trainBudgetMilliNodeHours = trainBudgetMilliNodeHours, 
        modelType = modelType), class = "gar_ImageClassificationModelMetadata")
}

#' PredictRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for PredictionService.Predict.
#' 
#' @param PredictRequest.params The \link{PredictRequest.params} object or list of objects
#' @param payload Required
#' @param params Additional domain-specific parameters, any string must be up to 25000 characters long
#' 
#' @return PredictRequest object
#' 
#' @family PredictRequest functions
#' @export
PredictRequest <- function(PredictRequest.params = NULL, payload = NULL, params = NULL) {
    structure(list(PredictRequest.params = PredictRequest.params, payload = payload, 
        params = params), class = "gar_PredictRequest")
}

#' PredictRequest.params Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Additional domain-specific parameters, any string must be up to 25000 characters long. AutoML Vision Classification `score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions for an image, it will only produce results that have at least this confidence score. The default is 0.5. AutoML Vision Object Detection `score_threshold` : (float) When Model detects objects on the image, it will only produce bounding boxes which have at least this confidence score. Value in 0 to 1 range, default is 0.5. `max_bounding_box_count` : (int64) The maximum number of bounding boxes returned. The default is 100. The number of returned bounding boxes might be limited by the server. AutoML Tables `feature_importance` : (boolean) Whether feature_importance is populated in the returned list of TablesAnnotation objects. The default is false.
#' 
#' 
#' 
#' @return PredictRequest.params object
#' 
#' @family PredictRequest functions
#' @export
PredictRequest.params <- function() {
    list()
}

#' Location Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A resource that represents Google Cloud Platform location.
#' 
#' @param Location.metadata The \link{Location.metadata} object or list of objects
#' @param Location.labels The \link{Location.labels} object or list of objects
#' @param metadata Service-specific metadata
#' @param displayName The friendly name for this location, typically a nearby city name
#' @param locationId The canonical id for this location
#' @param name Resource name for the location, which may vary between implementations
#' @param labels Cross-service attributes for the location
#' 
#' @return Location object
#' 
#' @family Location functions
#' @export
Location <- function(Location.metadata = NULL, Location.labels = NULL, metadata = NULL, 
    displayName = NULL, locationId = NULL, name = NULL, labels = NULL) {
    structure(list(Location.metadata = Location.metadata, Location.labels = Location.labels, 
        metadata = metadata, displayName = displayName, locationId = locationId, 
        name = name, labels = labels), class = "gar_Location")
}

#' Location.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Service-specific metadata. For example the available capacity at the given location.
#' 
#' 
#' 
#' @return Location.metadata object
#' 
#' @family Location functions
#' @export
Location.metadata <- function() {
    list()
}

#' Location.labels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Cross-service attributes for the location. For example {'cloud.googleapis.com/region': 'us-east1'}
#' 
#' 
#' 
#' @return Location.labels object
#' 
#' @family Location functions
#' @export
Location.labels <- function() {
    list()
}

#' ConfusionMatrix Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Confusion matrix of the model running the classification.
#' 
#' @param annotationSpecId Output only
#' @param displayName Output only
#' @param row Output only
#' 
#' @return ConfusionMatrix object
#' 
#' @family ConfusionMatrix functions
#' @export
ConfusionMatrix <- function(annotationSpecId = NULL, displayName = NULL, row = NULL) {
    structure(list(annotationSpecId = annotationSpecId, displayName = displayName, 
        row = row), class = "gar_ConfusionMatrix")
}

#' ListDatasetsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Response message for AutoMl.ListDatasets.
#' 
#' @param nextPageToken A token to retrieve next page of results
#' @param datasets The datasets read
#' 
#' @return ListDatasetsResponse object
#' 
#' @family ListDatasetsResponse functions
#' @export
ListDatasetsResponse <- function(nextPageToken = NULL, datasets = NULL) {
    structure(list(nextPageToken = nextPageToken, datasets = datasets), class = "gar_ListDatasetsResponse")
}

#' ListOperationsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The response message for Operations.ListOperations.
#' 
#' @param operations A list of operations that matches the specified filter in the request
#' @param nextPageToken The standard List next-page token
#' 
#' @return ListOperationsResponse object
#' 
#' @family ListOperationsResponse functions
#' @export
ListOperationsResponse <- function(operations = NULL, nextPageToken = NULL) {
    structure(list(operations = operations, nextPageToken = nextPageToken), class = "gar_ListOperationsResponse")
}

#' TextClassificationModelMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model metadata that is specific to text classification.
#' 
#' @param classificationType Output only
#' 
#' @return TextClassificationModelMetadata object
#' 
#' @family TextClassificationModelMetadata functions
#' @export
TextClassificationModelMetadata <- function(classificationType = NULL) {
    structure(list(classificationType = classificationType), class = "gar_TextClassificationModelMetadata")
}

#' ImageClassificationModelDeploymentMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model deployment metadata specific to Image Classification.
#' 
#' @param nodeCount Input only
#' 
#' @return ImageClassificationModelDeploymentMetadata object
#' 
#' @family ImageClassificationModelDeploymentMetadata functions
#' @export
ImageClassificationModelDeploymentMetadata <- function(nodeCount = NULL) {
    structure(list(nodeCount = nodeCount), class = "gar_ImageClassificationModelDeploymentMetadata")
}

#' DocumentInputConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Input configuration of a Document.
#' 
#' @param gcsSource The Google Cloud Storage location of the document file
#' 
#' @return DocumentInputConfig object
#' 
#' @family DocumentInputConfig functions
#' @export
DocumentInputConfig <- function(gcsSource = NULL) {
    structure(list(gcsSource = gcsSource), class = "gar_DocumentInputConfig")
}

#' ClassificationAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Contains annotation details specific to classification.
#' 
#' @param score Output only
#' 
#' @return ClassificationAnnotation object
#' 
#' @family ClassificationAnnotation functions
#' @export
ClassificationAnnotation <- function(score = NULL) {
    structure(list(score = score), class = "gar_ClassificationAnnotation")
}

#' Empty Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`.
#' 
#' 
#' 
#' @return Empty object
#' 
#' @family Empty functions
#' @export
Empty <- function() {
    list()
}

#' BatchPredictRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for PredictionService.BatchPredict.
#' 
#' @param BatchPredictRequest.params The \link{BatchPredictRequest.params} object or list of objects
#' @param outputConfig Required
#' @param params Additional domain-specific parameters for the predictions, any string must be up to 25000 characters long
#' @param inputConfig Required
#' 
#' @return BatchPredictRequest object
#' 
#' @family BatchPredictRequest functions
#' @export
BatchPredictRequest <- function(BatchPredictRequest.params = NULL, outputConfig = NULL, 
    params = NULL, inputConfig = NULL) {
    structure(list(BatchPredictRequest.params = BatchPredictRequest.params, outputConfig = outputConfig, 
        params = params, inputConfig = inputConfig), class = "gar_BatchPredictRequest")
}

#' BatchPredictRequest.params Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Additional domain-specific parameters for the predictions, any string must be up to 25000 characters long. AutoML Natural Language Classification `score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions for a text snippet, it will only produce results that have at least this confidence score. The default is 0.5. AutoML Vision Classification `score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions for an image, it will only produce results that have at least this confidence score. The default is 0.5. AutoML Vision Object Detection `score_threshold` : (float) When Model detects objects on the image, it will only produce bounding boxes which have at least this confidence score. Value in 0 to 1 range, default is 0.5. `max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per image. The default is 100, the number of bounding boxes returned might be limited by the server. AutoML Video Intelligence Classification `score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions for a video, it will only produce results that have at least this confidence score. The default is 0.5. `segment_classification` : (boolean) Set to true to request segment-level classification. AutoML Video Intelligence returns labels and their confidence scores for the entire segment of the video that user specified in the request configuration. The default is true. `shot_classification` : (boolean) Set to true to request shot-level classification. AutoML Video Intelligence determines the boundaries for each camera shot in the entire segment of the video that user specified in the request configuration. AutoML Video Intelligence then returns labels and their confidence scores for each detected shot, along with the start and end time of the shot. The default is false. WARNING: Model evaluation is not done for this classification type, the quality of it depends on training data, but there are no metrics provided to describe that quality. `1s_interval_classification` : (boolean) Set to true to request classification for a video at one-second intervals. AutoML Video Intelligence returns labels and their confidence scores for each second of the entire segment of the video that user specified in the request configuration. The default is false. WARNING: Model evaluation is not done for this classification type, the quality of it depends on training data, but there are no metrics provided to describe that quality. AutoML Video Intelligence Object Tracking `score_threshold` : (float) When Model detects objects on video frames, it will only produce bounding boxes which have at least this confidence score. Value in 0 to 1 range, default is 0.5. `max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per image. The default is 100, the number of bounding boxes returned might be limited by the server. `min_bounding_box_size` : (float) Only bounding boxes with shortest edge at least that long as a relative value of video frame size are returned. Value in 0 to 1 range. Default is 0. 
#' 
#' 
#' 
#' @return BatchPredictRequest.params object
#' 
#' @family BatchPredictRequest functions
#' @export
BatchPredictRequest.params <- function() {
    list()
}

#' DeleteOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of operations that perform deletes of any entities.
#' 
#' 
#' 
#' @return DeleteOperationMetadata object
#' 
#' @family DeleteOperationMetadata functions
#' @export
DeleteOperationMetadata <- function() {
    list()
}

#' ExportModelRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for AutoMl.ExportModel. Models need to be enabled for exporting, otherwise an error code will be returned.
#' 
#' @param outputConfig Required
#' 
#' @return ExportModelRequest object
#' 
#' @family ExportModelRequest functions
#' @export
ExportModelRequest <- function(outputConfig = NULL) {
    structure(list(outputConfig = outputConfig), class = "gar_ExportModelRequest")
}

#' ExportDataOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of ExportData operation.
#' 
#' @param outputInfo Output only
#' 
#' @return ExportDataOperationMetadata object
#' 
#' @family ExportDataOperationMetadata functions
#' @export
ExportDataOperationMetadata <- function(outputInfo = NULL) {
    structure(list(outputInfo = outputInfo), class = "gar_ExportDataOperationMetadata")
}

#' OperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Metadata used across all long running operations returned by AutoML API.
#' 
#' @param partialFailures Output only
#' @param updateTime Output only
#' @param importDataDetails Details of ImportData operation
#' @param createDatasetDetails Details of CreateDataset operation
#' @param createTime Output only
#' @param undeployModelDetails Details of an UndeployModel operation
#' @param progressPercent Output only
#' @param exportDataDetails Details of ExportData operation
#' @param deleteDetails Details of a Delete operation
#' @param batchPredictDetails Details of BatchPredict operation
#' @param createModelDetails Details of CreateModel operation
#' @param deployModelDetails Details of a DeployModel operation
#' @param exportModelDetails Details of ExportModel operation
#' 
#' @return OperationMetadata object
#' 
#' @family OperationMetadata functions
#' @export
OperationMetadata <- function(partialFailures = NULL, updateTime = NULL, importDataDetails = NULL, 
    createDatasetDetails = NULL, createTime = NULL, undeployModelDetails = NULL, 
    progressPercent = NULL, exportDataDetails = NULL, deleteDetails = NULL, batchPredictDetails = NULL, 
    createModelDetails = NULL, deployModelDetails = NULL, exportModelDetails = NULL) {
    structure(list(partialFailures = partialFailures, updateTime = updateTime, importDataDetails = importDataDetails, 
        createDatasetDetails = createDatasetDetails, createTime = createTime, undeployModelDetails = undeployModelDetails, 
        progressPercent = progressPercent, exportDataDetails = exportDataDetails, 
        deleteDetails = deleteDetails, batchPredictDetails = batchPredictDetails, 
        createModelDetails = createModelDetails, deployModelDetails = deployModelDetails, 
        exportModelDetails = exportModelDetails), class = "gar_OperationMetadata")
}

#' TextSentimentEvaluationMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model evaluation metrics for text sentiment problems.
#' 
#' @param quadraticKappa Output only
#' @param confusionMatrix Output only
#' @param linearKappa Output only
#' @param meanSquaredError Output only
#' @param meanAbsoluteError Output only
#' @param f1Score Output only
#' @param precision Output only
#' @param recall Output only
#' 
#' @return TextSentimentEvaluationMetrics object
#' 
#' @family TextSentimentEvaluationMetrics functions
#' @export
TextSentimentEvaluationMetrics <- function(quadraticKappa = NULL, confusionMatrix = NULL, 
    linearKappa = NULL, meanSquaredError = NULL, meanAbsoluteError = NULL, f1Score = NULL, 
    precision = NULL, recall = NULL) {
    structure(list(quadraticKappa = quadraticKappa, confusionMatrix = confusionMatrix, 
        linearKappa = linearKappa, meanSquaredError = meanSquaredError, meanAbsoluteError = meanAbsoluteError, 
        f1Score = f1Score, precision = precision, recall = recall), class = "gar_TextSentimentEvaluationMetrics")
}

#' Document Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A structured text document e.g. a PDF.
#' 
#' @param documentText The plain text version of this document
#' @param documentDimensions The dimensions of the page in the document
#' @param layout Describes the layout of the document
#' @param pageCount Number of pages in the document
#' @param inputConfig An input config specifying the content of the document
#' 
#' @return Document object
#' 
#' @family Document functions
#' @export
Document <- function(documentText = NULL, documentDimensions = NULL, layout = NULL, 
    pageCount = NULL, inputConfig = NULL) {
    structure(list(documentText = documentText, documentDimensions = documentDimensions, 
        layout = layout, pageCount = pageCount, inputConfig = inputConfig), class = "gar_Document")
}

#' AnnotationPayload Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Contains annotation information that is relevant to AutoML.
#' 
#' @param textSentiment Annotation details for text sentiment
#' @param displayName Output only
#' @param textExtraction Annotation details for text extraction
#' @param annotationSpecId Output only 
#' @param imageObjectDetection Annotation details for image object detection
#' @param classification Annotation details for content or image classification
#' @param translation Annotation details for translation
#' 
#' @return AnnotationPayload object
#' 
#' @family AnnotationPayload functions
#' @export
AnnotationPayload <- function(textSentiment = NULL, displayName = NULL, textExtraction = NULL, 
    annotationSpecId = NULL, imageObjectDetection = NULL, classification = NULL, 
    translation = NULL) {
    structure(list(textSentiment = textSentiment, displayName = displayName, textExtraction = textExtraction, 
        annotationSpecId = annotationSpecId, imageObjectDetection = imageObjectDetection, 
        classification = classification, translation = translation), class = "gar_AnnotationPayload")
}

#' Expr Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: 'Summary size limit' description: 'Determines if a summary is less than 100 chars' expression: 'document.summary.size() < 100' Example (Equality): title: 'Requestor is owner' description: 'Determines if requestor is the document owner' expression: 'document.owner == request.auth.claims.email' Example (Logic): title: 'Public documents' description: 'Determine whether the document should be publicly visible' expression: 'document.type != 'private' && document.type != 'internal'' Example (Data Manipulation): title: 'Notification string' description: 'Create a notification string with a timestamp.' expression: ''New message received at ' + string(document.create_time)' The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
#' 
#' @param description Optional
#' @param expression Textual representation of an expression in Common Expression Language syntax
#' @param location Optional
#' @param title Optional
#' 
#' @return Expr object
#' 
#' @family Expr functions
#' @export
Expr <- function(description = NULL, expression = NULL, location = NULL, title = NULL) {
    structure(list(description = description, expression = expression, location = location, 
        title = title), class = "gar_Expr")
}

#' ExamplePayload Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Example data used for training or prediction.
#' 
#' @param image Example image
#' @param textSnippet Example text
#' @param document Example document
#' 
#' @return ExamplePayload object
#' 
#' @family ExamplePayload functions
#' @export
ExamplePayload <- function(image = NULL, textSnippet = NULL, document = NULL) {
    structure(list(image = image, textSnippet = textSnippet, document = document), 
        class = "gar_ExamplePayload")
}

#' ImportDataRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for AutoMl.ImportData.
#' 
#' @param inputConfig Required
#' 
#' @return ImportDataRequest object
#' 
#' @family ImportDataRequest functions
#' @export
ImportDataRequest <- function(inputConfig = NULL) {
    structure(list(inputConfig = inputConfig), class = "gar_ImportDataRequest")
}

#' ImageObjectDetectionModelDeploymentMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model deployment metadata specific to Image Object Detection.
#' 
#' @param nodeCount Input only
#' 
#' @return ImageObjectDetectionModelDeploymentMetadata object
#' 
#' @family ImageObjectDetectionModelDeploymentMetadata functions
#' @export
ImageObjectDetectionModelDeploymentMetadata <- function(nodeCount = NULL) {
    structure(list(nodeCount = nodeCount), class = "gar_ImageObjectDetectionModelDeploymentMetadata")
}

#' TextSentimentAnnotation Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Contains annotation details specific to text sentiment.
#' 
#' @param sentiment Output only
#' 
#' @return TextSentimentAnnotation object
#' 
#' @family TextSentimentAnnotation functions
#' @export
TextSentimentAnnotation <- function(sentiment = NULL) {
    structure(list(sentiment = sentiment), class = "gar_TextSentimentAnnotation")
}

#' ListLocationsResponse Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' The response message for Locations.ListLocations.
#' 
#' @param locations A list of locations that matches the specified filter in the request
#' @param nextPageToken The standard List next-page token
#' 
#' @return ListLocationsResponse object
#' 
#' @family ListLocationsResponse functions
#' @export
ListLocationsResponse <- function(locations = NULL, nextPageToken = NULL) {
    structure(list(locations = locations, nextPageToken = nextPageToken), class = "gar_ListLocationsResponse")
}

#' DeployModelRequest Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Request message for AutoMl.DeployModel.
#' 
#' @param imageObjectDetectionModelDeploymentMetadata Model deployment metadata specific to Image Object Detection
#' @param imageClassificationModelDeploymentMetadata Model deployment metadata specific to Image Classification
#' 
#' @return DeployModelRequest object
#' 
#' @family DeployModelRequest functions
#' @export
DeployModelRequest <- function(imageObjectDetectionModelDeploymentMetadata = NULL, 
    imageClassificationModelDeploymentMetadata = NULL) {
    structure(list(imageObjectDetectionModelDeploymentMetadata = imageObjectDetectionModelDeploymentMetadata, 
        imageClassificationModelDeploymentMetadata = imageClassificationModelDeploymentMetadata), 
        class = "gar_DeployModelRequest")
}

#' BatchPredictResult Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Result of the Batch Predict. This message is returned in response of the operation returned by the PredictionService.BatchPredict.
#' 
#' @param BatchPredictResult.metadata The \link{BatchPredictResult.metadata} object or list of objects
#' @param metadata Additional domain-specific prediction response metadata
#' 
#' @return BatchPredictResult object
#' 
#' @family BatchPredictResult functions
#' @export
BatchPredictResult <- function(BatchPredictResult.metadata = NULL, metadata = NULL) {
    structure(list(BatchPredictResult.metadata = BatchPredictResult.metadata, metadata = metadata), 
        class = "gar_BatchPredictResult")
}

#' BatchPredictResult.metadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Additional domain-specific prediction response metadata. AutoML Vision Object Detection `max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per image. AutoML Video Intelligence Object Tracking `max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per frame.
#' 
#' 
#' 
#' @return BatchPredictResult.metadata object
#' 
#' @family BatchPredictResult functions
#' @export
BatchPredictResult.metadata <- function() {
    list()
}

#' TextSegment Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A contiguous part of a text (string), assuming it has an UTF-8 NFC encoding.
#' 
#' @param endOffset Required
#' @param startOffset Required
#' @param content Output only
#' 
#' @return TextSegment object
#' 
#' @family TextSegment functions
#' @export
TextSegment <- function(endOffset = NULL, startOffset = NULL, content = NULL) {
    structure(list(endOffset = endOffset, startOffset = startOffset, content = content), 
        class = "gar_TextSegment")
}

#' BoundingBoxMetricsEntry Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Bounding box matching model metrics for a single intersection-over-union threshold and multiple label match confidence thresholds.
#' 
#' @param iouThreshold Output only
#' @param meanAveragePrecision Output only
#' @param confidenceMetricsEntries Output only
#' 
#' @return BoundingBoxMetricsEntry object
#' 
#' @family BoundingBoxMetricsEntry functions
#' @export
BoundingBoxMetricsEntry <- function(iouThreshold = NULL, meanAveragePrecision = NULL, 
    confidenceMetricsEntries = NULL) {
    structure(list(iouThreshold = iouThreshold, meanAveragePrecision = meanAveragePrecision, 
        confidenceMetricsEntries = confidenceMetricsEntries), class = "gar_BoundingBoxMetricsEntry")
}

#' CreateModelOperationMetadata Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Details of CreateModel operation.
#' 
#' 
#' 
#' @return CreateModelOperationMetadata object
#' 
#' @family CreateModelOperationMetadata functions
#' @export
CreateModelOperationMetadata <- function() {
    list()
}

#' ClassificationEvaluationMetrics Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Model evaluation metrics for classification problems. Note: For Video Classification this metrics only describe quality of the Video Classification predictions of 'segment_classification' type.
#' 
#' @param auRoc Output only
#' @param logLoss Output only
#' @param confusionMatrix Output only
#' @param auPrc Output only
#' @param annotationSpecId Output only
#' @param confidenceMetricsEntry Output only
#' 
#' @return ClassificationEvaluationMetrics object
#' 
#' @family ClassificationEvaluationMetrics functions
#' @export
ClassificationEvaluationMetrics <- function(auRoc = NULL, logLoss = NULL, confusionMatrix = NULL, 
    auPrc = NULL, annotationSpecId = NULL, confidenceMetricsEntry = NULL) {
    structure(list(auRoc = auRoc, logLoss = logLoss, confusionMatrix = confusionMatrix, 
        auPrc = auPrc, annotationSpecId = annotationSpecId, confidenceMetricsEntry = confidenceMetricsEntry), 
        class = "gar_ClassificationEvaluationMetrics")
}

#' OutputConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' * For Translation: CSV file `translation.csv`, with each line in format: ML_USE,GCS_FILE_PATH GCS_FILE_PATH leads to a .TSV file which describes examples that have given ML_USE, using the following row format per line: TEXT_SNIPPET (in source language) \t TEXT_SNIPPET (in target language) * For Tables: Output depends on whether the dataset was imported from Google Cloud Storage or BigQuery. Google Cloud Storage case: gcs_destination must be set. Exported are CSV file(s) `tables_1.csv`, `tables_2.csv`,...,`tables_N.csv` with each having as header line the table's column names, and all other lines contain values for the header columns. BigQuery case: bigquery_destination pointing to a BigQuery project must be set. In the given project a new dataset will be created with name `export_data__` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores), and timestamp will be in YYYY_MM_DDThh_mm_ss_sssZ 'based on ISO-8601' format. In that dataset a new table called `primary_table` will be created, and filled with precisely the same data as this obtained on import.
#' 
#' @param gcsDestination Required
#' 
#' @return OutputConfig object
#' 
#' @family OutputConfig functions
#' @export
OutputConfig <- function(gcsDestination = NULL) {
    structure(list(gcsDestination = gcsDestination), class = "gar_OutputConfig")
}

#' InputConfig Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Input configuration for AutoMl.ImportData action. The format of input depends on dataset_metadata the Dataset into which the import is happening has. As input source the gcs_source is expected, unless specified otherwise. Additionally any input .CSV file by itself must be 100MB or smaller, unless specified otherwise. If an 'example' file (that is, image, video etc.) with identical content (even if it had different `GCS_FILE_PATH`) is mentioned multiple times, then its label, bounding boxes etc. are appended. The same file should be always provided with the same `ML_USE` and `GCS_FILE_PATH`, if it is not, then these values are nondeterministically selected from the given ones. The formats are represented in EBNF with commas being literal and with non-terminal symbols defined near the end of this comment. The formats are: AutoML Vision Classification See [Preparing your training data](https://cloud.google.com/vision/automl/docs/prepare) for more information. CSV file(s) with each line in format: ML_USE,GCS_FILE_PATH,LABEL,LABEL,... * `ML_USE` - Identifies the data set that the current row (file) applies to. This value can be one of the following: * `TRAIN` - Rows in this file are used to train the model. * `TEST` - Rows in this file are used to test the model during training. * `UNASSIGNED` - Rows in this file are not categorized. They are Automatically divided into train and test data. 80% for training and 20% for testing. * `GCS_FILE_PATH` - The Google Cloud Storage location of an image of up to 30MB in size. Supported extensions: .JPEG, .GIF, .PNG, .WEBP, .BMP, .TIFF, .ICO. * `LABEL` - A label that identifies the object in the image. For the `MULTICLASS` classification type, at most one `LABEL` is allowed per image. If an image has not yet been labeled, then it should be mentioned just once with no `LABEL`. Some sample rows: TRAIN,gs://folder/image1.jpg,daisy TEST,gs://folder/image2.jpg,dandelion,tulip,rose UNASSIGNED,gs://folder/image3.jpg,daisy UNASSIGNED,gs://folder/image4.jpg Object Detection See [Preparing your training data](https://cloud.google.com/vision/automl/object-detection/docs/prepare) for more information. A CSV file(s) with each line in format: ML_USE,GCS_FILE_PATH,[LABEL],(BOUNDING_BOX | ,,,,,,,) * `ML_USE` - Identifies the data set that the current row (file) applies to. This value can be one of the following: * `TRAIN` - Rows in this file are used to train the model. * `TEST` - Rows in this file are used to test the model during training. * `UNASSIGNED` - Rows in this file are not categorized. They are Automatically divided into train and test data. 80% for training and 20% for testing. * `GCS_FILE_PATH` - The Google Cloud Storage location of an image of up to 30MB in size. Supported extensions: .JPEG, .GIF, .PNG. Each image is assumed to be exhaustively labeled. * `LABEL` - A label that identifies the object in the image specified by the `BOUNDING_BOX`. * `BOUNDING BOX` - The vertices of an object in the example image. The minimum allowed `BOUNDING_BOX` edge length is 0.01, and no more than 500 `BOUNDING_BOX` instances per image are allowed (one `BOUNDING_BOX` per line). If an image has no looked for objects then it should be mentioned just once with no LABEL and the ',,,,,,,' in place of the `BOUNDING_BOX`. **Four sample rows:** TRAIN,gs://folder/image1.png,car,0.1,0.1,,,0.3,0.3,, TRAIN,gs://folder/image1.png,bike,.7,.6,,,.8,.9,, UNASSIGNED,gs://folder/im2.png,car,0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.3 TEST,gs://folder/im3.png,,,,,,,,, AutoML Video Intelligence Classification See [Preparing your training data](https://cloud.google.com/video-intelligence/automl/docs/prepare) for more information. CSV file(s) with each line in format: ML_USE,GCS_FILE_PATH For `ML_USE`, do not use `VALIDATE`. `GCS_FILE_PATH` is the path to another .csv file that describes training example for a given `ML_USE`, using the following row format: GCS_FILE_PATH,(LABEL,TIME_SEGMENT_START,TIME_SEGMENT_END | ,,) Here `GCS_FILE_PATH` leads to a video of up to 50GB in size and up to 3h duration. Supported extensions: .MOV, .MPEG4, .MP4, .AVI. `TIME_SEGMENT_START` and `TIME_SEGMENT_END` must be within the length of the video, and the end time must be after the start time. Any segment of a video which has one or more labels on it, is considered a hard negative for all other labels. Any segment with no labels on it is considered to be unknown. If a whole video is unknown, then it should be mentioned just once with ',,' in place of `LABEL, TIME_SEGMENT_START,TIME_SEGMENT_END`. Sample top level CSV file: TRAIN,gs://folder/train_videos.csv TEST,gs://folder/test_videos.csv UNASSIGNED,gs://folder/other_videos.csv Sample rows of a CSV file for a particular ML_USE: gs://folder/video1.avi,car,120,180.000021 gs://folder/video1.avi,bike,150,180.000021 gs://folder/vid2.avi,car,0,60.5 gs://folder/vid3.avi,,, Object Tracking See [Preparing your training data](/video-intelligence/automl/object-tracking/docs/prepare) for more information. CSV file(s) with each line in format: ML_USE,GCS_FILE_PATH For `ML_USE`, do not use `VALIDATE`. `GCS_FILE_PATH` is the path to another .csv file that describes training example for a given `ML_USE`, using the following row format: GCS_FILE_PATH,LABEL,[INSTANCE_ID],TIMESTAMP,BOUNDING_BOX or GCS_FILE_PATH,,,,,,,,,, Here `GCS_FILE_PATH` leads to a video of up to 50GB in size and up to 3h duration. Supported extensions: .MOV, .MPEG4, .MP4, .AVI. Providing `INSTANCE_ID`s can help to obtain a better model. When a specific labeled entity leaves the video frame, and shows up afterwards it is not required, albeit preferable, that the same `INSTANCE_ID` is given to it. `TIMESTAMP` must be within the length of the video, the `BOUNDING_BOX` is assumed to be drawn on the closest video's frame to the `TIMESTAMP`. Any mentioned by the `TIMESTAMP` frame is expected to be exhaustively labeled and no more than 500 `BOUNDING_BOX`-es per frame are allowed. If a whole video is unknown, then it should be mentioned just once with ',,,,,,,,,,' in place of `LABEL, [INSTANCE_ID],TIMESTAMP,BOUNDING_BOX`. Sample top level CSV file: TRAIN,gs://folder/train_videos.csv TEST,gs://folder/test_videos.csv UNASSIGNED,gs://folder/other_videos.csv Seven sample rows of a CSV file for a particular ML_USE: gs://folder/video1.avi,car,1,12.10,0.8,0.8,0.9,0.8,0.9,0.9,0.8,0.9 gs://folder/video1.avi,car,1,12.90,0.4,0.8,0.5,0.8,0.5,0.9,0.4,0.9 gs://folder/video1.avi,car,2,12.10,.4,.2,.5,.2,.5,.3,.4,.3 gs://folder/video1.avi,car,2,12.90,.8,.2,,,.9,.3,, gs://folder/video1.avi,bike,,12.50,.45,.45,,,.55,.55,, gs://folder/video2.avi,car,1,0,.1,.9,,,.9,.1,, gs://folder/video2.avi,,,,,,,,,,, AutoML Natural Language Entity Extraction See [Preparing your training data](/natural-language/automl/entity-analysis/docs/prepare) for more information. One or more CSV file(s) with each line in the following format: ML_USE,GCS_FILE_PATH * `ML_USE` - Identifies the data set that the current row (file) applies to. This value can be one of the following: * `TRAIN` - Rows in this file are used to train the model. * `TEST` - Rows in this file are used to test the model during training. * `UNASSIGNED` - Rows in this file are not categorized. They are Automatically divided into train and test data. 80% for training and 20% for testing.. * `GCS_FILE_PATH` - a Identifies JSON Lines (.JSONL) file stored in Google Cloud Storage that contains in-line text in-line as documents for model training. After the training data set has been determined from the `TRAIN` and `UNASSIGNED` CSV files, the training data is divided into train and validation data sets. 70% for training and 30% for validation. For example: TRAIN,gs://folder/file1.jsonl VALIDATE,gs://folder/file2.jsonl TEST,gs://folder/file3.jsonl **In-line JSONL files** In-line .JSONL files contain, per line, a JSON document that wraps a `text_snippet` field followed by one or more `annotations` fields, which have `display_name` and `text_extraction` fields to describe the entity from the text snippet. Multiple JSON documents can be separated using line breaks (\n). The supplied text must be annotated exhaustively. For example, if you include the text 'horse', but do not label it as 'animal', then 'horse' is assumed to not be an 'animal'. Any given text snippet content must have 30,000 characters or less, and also be UTF-8 NFC encoded. ASCII is accepted as it is UTF-8 NFC encoded. For example: { 'text_snippet': { 'content': 'dog car cat' }, 'annotations': [ { 'display_name': 'animal', 'text_extraction': { 'text_segment': {'start_offset': 0, 'end_offset': 2} } }, { 'display_name': 'vehicle', 'text_extraction': { 'text_segment': {'start_offset': 4, 'end_offset': 6} } }, { 'display_name': 'animal', 'text_extraction': { 'text_segment': {'start_offset': 8, 'end_offset': 10} } } ] }\n { 'text_snippet': { 'content': 'This dog is good.' }, 'annotations': [ { 'display_name': 'animal', 'text_extraction': { 'text_segment': {'start_offset': 5, 'end_offset': 7} } } ] } **JSONL files that reference documents** .JSONL files contain, per line, a JSON document that wraps a `input_config` that contains the path to a source document. Multiple JSON documents can be separated using line breaks (\n). Supported document extensions: .PDF, .TIF, .TIFF For example: { 'document': { 'input_config': { 'gcs_source': { 'input_uris': [ 'gs://folder/document1.pdf' ] } } } }\n { 'document': { 'input_config': { 'gcs_source': { 'input_uris': [ 'gs://folder/document2.tif' ] } } } } **In-line JSONL files with document layout information** **Note:** You can only annotate documents using the UI. The format described below applies to annotated documents exported using the UI or `exportData`. In-line .JSONL files for documents contain, per line, a JSON document that wraps a `document` field that provides the textual content of the document and the layout information. For example: { 'document': { 'document_text': { 'content': 'dog car cat' } 'layout': [ { 'text_segment': { 'start_offset': 0, 'end_offset': 11, }, 'page_number': 1, 'bounding_poly': { 'normalized_vertices': [ {'x': 0.1, 'y': 0.1}, {'x': 0.1, 'y': 0.3}, {'x': 0.3, 'y': 0.3}, {'x': 0.3, 'y': 0.1}, ], }, 'text_segment_type': TOKEN, } ], 'document_dimensions': { 'width': 8.27, 'height': 11.69, 'unit': INCH, } 'page_count': 3, }, 'annotations': [ { 'display_name': 'animal', 'text_extraction': { 'text_segment': {'start_offset': 0, 'end_offset': 3} } }, { 'display_name': 'vehicle', 'text_extraction': { 'text_segment': {'start_offset': 4, 'end_offset': 7} } }, { 'display_name': 'animal', 'text_extraction': { 'text_segment': {'start_offset': 8, 'end_offset': 11} } }, ], Classification See [Preparing your training data](https://cloud.google.com/natural-language/automl/docs/prepare) for more information. One or more CSV file(s) with each line in the following format: ML_USE,(TEXT_SNIPPET | GCS_FILE_PATH),LABEL,LABEL,... * `ML_USE` - Identifies the data set that the current row (file) applies to. This value can be one of the following: * `TRAIN` - Rows in this file are used to train the model. * `TEST` - Rows in this file are used to test the model during training. * `UNASSIGNED` - Rows in this file are not categorized. They are Automatically divided into train and test data. 80% for training and 20% for testing. * `TEXT_SNIPPET` and `GCS_FILE_PATH` are distinguished by a pattern. If the column content is a valid Google Cloud Storage file path, that is, prefixed by 'gs://', it is treated as a `GCS_FILE_PATH`. Otherwise, if the content is enclosed in double quotes (''), it is treated as a `TEXT_SNIPPET`. For `GCS_FILE_PATH`, the path must lead to a file with supported extension and UTF-8 encoding, for example, 'gs://folder/content.txt' AutoML imports the file content as a text snippet. For `TEXT_SNIPPET`, AutoML imports the column content excluding quotes. In both cases, size of the content must be 10MB or less in size. For zip files, the size of each file inside the zip must be 10MB or less in size. For the `MULTICLASS` classification type, at most one `LABEL` is allowed. The `ML_USE` and `LABEL` columns are optional. Supported file extensions: .TXT, .PDF, .TIF, .TIFF, .ZIP A maximum of 100 unique labels are allowed per CSV row. Sample rows: TRAIN,'They have bad food and very rude',RudeService,BadFood gs://folder/content.txt,SlowService TEST,gs://folder/document.pdf VALIDATE,gs://folder/text_files.zip,BadFood Sentiment Analysis See [Preparing your training data](https://cloud.google.com/natural-language/automl/docs/prepare) for more information. CSV file(s) with each line in format: ML_USE,(TEXT_SNIPPET | GCS_FILE_PATH),SENTIMENT * `ML_USE` - Identifies the data set that the current row (file) applies to. This value can be one of the following: * `TRAIN` - Rows in this file are used to train the model. * `TEST` - Rows in this file are used to test the model during training. * `UNASSIGNED` - Rows in this file are not categorized. They are Automatically divided into train and test data. 80% for training and 20% for testing. * `TEXT_SNIPPET` and `GCS_FILE_PATH` are distinguished by a pattern. If the column content is a valid Google Cloud Storage file path, that is, prefixed by 'gs://', it is treated as a `GCS_FILE_PATH`. Otherwise, if the content is enclosed in double quotes (''), it is treated as a `TEXT_SNIPPET`. For `GCS_FILE_PATH`, the path must lead to a file with supported extension and UTF-8 encoding, for example, 'gs://folder/content.txt' AutoML imports the file content as a text snippet. For `TEXT_SNIPPET`, AutoML imports the column content excluding quotes. In both cases, size of the content must be 128kB or less in size. For zip files, the size of each file inside the zip must be 128kB or less in size. The `ML_USE` and `SENTIMENT` columns are optional. Supported file extensions: .TXT, .PDF, .TIF, .TIFF, .ZIP * `SENTIMENT` - An integer between 0 and Dataset.text_sentiment_dataset_metadata.sentiment_max (inclusive). Describes the ordinal of the sentiment - higher value means a more positive sentiment. All the values are completely relative, i.e. neither 0 needs to mean a negative or neutral sentiment nor sentiment_max needs to mean a positive one - it is just required that 0 is the least positive sentiment in the data, and sentiment_max is the most positive one. The SENTIMENT shouldn't be confused with 'score' or 'magnitude' from the previous Natural Language Sentiment Analysis API. All SENTIMENT values between 0 and sentiment_max must be represented in the imported data. On prediction the same 0 to sentiment_max range will be used. The difference between neighboring sentiment values needs not to be uniform, e.g. 1 and 2 may be similar whereas the difference between 2 and 3 may be large. Sample rows: TRAIN,'@freewrytin this is way too good for your product',2 gs://folder/content.txt,3 TEST,gs://folder/document.pdf VALIDATE,gs://folder/text_files.zip,2 AutoML Tables See [Preparing your training data](https://cloud.google.com/automl-tables/docs/prepare) for more information. You can use either gcs_source or bigquery_source. All input is concatenated into a single primary_table_spec_id **For gcs_source:** CSV file(s), where the first row of the first file is the header, containing unique column names. If the first row of a subsequent file is the same as the header, then it is also treated as a header. All other rows contain values for the corresponding columns. Each .CSV file by itself must be 10GB or smaller, and their total size must be 100GB or smaller. First three sample rows of a CSV file: 'Id','First Name','Last Name','Dob','Addresses' '1','John','Doe','1968-01-22','[{'status':'current','address':'123_First_Avenue','city':'Seattle','state':'WA','zip':'11111','numberOfYears':'1'},{'status':'previous','address':'456_Main_Street','city':'Portland','state':'OR','zip':'22222','numberOfYears':'5'}]' '2','Jane','Doe','1980-10-16','[{'status':'current','address':'789_Any_Avenue','city':'Albany','state':'NY','zip':'33333','numberOfYears':'2'},{'status':'previous','address':'321_Main_Street','city':'Hoboken','state':'NJ','zip':'44444','numberOfYears':'3'}]} **For bigquery_source:** An URI of a BigQuery table. The user data size of the BigQuery table must be 100GB or smaller. An imported table must have between 2 and 1,000 columns, inclusive, and between 1000 and 100,000,000 rows, inclusive. There are at most 5 import data running in parallel. **Input field definitions:** `ML_USE` : ('TRAIN' | 'VALIDATE' | 'TEST' | 'UNASSIGNED') Describes how the given example (file) should be used for model training. 'UNASSIGNED' can be used when user has no preference. `GCS_FILE_PATH` : The path to a file on Google Cloud Storage. For example, 'gs://folder/image1.png'. `LABEL` : A display name of an object on an image, video etc., e.g. 'dog'. Must be up to 32 characters long and can consist only of ASCII Latin letters A-Z and a-z, underscores(_), and ASCII digits 0-9. For each label an AnnotationSpec is created which display_name becomes the label; AnnotationSpecs are given back in predictions. `INSTANCE_ID` : A positive integer that identifies a specific instance of a labeled entity on an example. Used e.g. to track two cars on a video while being able to tell apart which one is which. `BOUNDING_BOX` : (`VERTEX,VERTEX,VERTEX,VERTEX` | `VERTEX,,,VERTEX,,`) A rectangle parallel to the frame of the example (image, video). If 4 vertices are given they are connected by edges in the order provided, if 2 are given they are recognized as diagonally opposite vertices of the rectangle. `VERTEX` : (`COORDINATE,COORDINATE`) First coordinate is horizontal (x), the second is vertical (y). `COORDINATE` : A float in 0 to 1 range, relative to total length of image or video in given dimension. For fractions the leading non-decimal 0 can be omitted (i.e. 0.3 = .3). Point 0,0 is in top left. `TIME_SEGMENT_START` : (`TIME_OFFSET`) Expresses a beginning, inclusive, of a time segment within an example that has a time dimension (e.g. video). `TIME_SEGMENT_END` : (`TIME_OFFSET`) Expresses an end, exclusive, of a time segment within n example that has a time dimension (e.g. video). `TIME_OFFSET` : A number of seconds as measured from the start of an example (e.g. video). Fractions are allowed, up to a microsecond precision. 'inf' is allowed, and it means the end of the example. `TEXT_SNIPPET` : The content of a text snippet, UTF-8 encoded, enclosed within double quotes (''). `DOCUMENT` : A field that provides the textual content with document and the layout information. **Errors:** If any of the provided CSV files can't be parsed or if more than certain percent of CSV rows cannot be processed then the operation fails and nothing is imported. Regardless of overall success or failure the per-row failures, up to a certain count cap, is listed in Operation.metadata.partial_failures. 
#' 
#' @param InputConfig.params The \link{InputConfig.params} object or list of objects
#' @param params Additional domain-specific parameters describing the semantic of the imported data, any string must be up to 25000 characters long
#' @param gcsSource The Google Cloud Storage location for the input content
#' 
#' @return InputConfig object
#' 
#' @family InputConfig functions
#' @export
InputConfig <- function(InputConfig.params = NULL, params = NULL, gcsSource = NULL) {
    structure(list(InputConfig.params = InputConfig.params, params = params, gcsSource = gcsSource), 
        class = "gar_InputConfig")
}

#' InputConfig.params Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Additional domain-specific parameters describing the semantic of the imported data, any string must be up to 25000 characters long. AutoML Tables `schema_inference_version` : (integer) This value must be supplied. The version of the algorithm to use for the initial inference of the column data types of the imported table. Allowed values: '1'.
#' 
#' 
#' 
#' @return InputConfig.params object
#' 
#' @family InputConfig functions
#' @export
InputConfig.params <- function() {
    list()
}

#' Model Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' API proto representing a trained machine learning model.
#' 
#' @param Model.labels The \link{Model.labels} object or list of objects
#' @param imageObjectDetectionModelMetadata Metadata for image object detection models
#' @param deploymentState Output only
#' @param datasetId Required
#' @param labels Optional
#' @param textSentimentModelMetadata Metadata for text sentiment models
#' @param translationModelMetadata Metadata for translation models
#' @param name Output only
#' @param textClassificationModelMetadata Metadata for text classification models
#' @param textExtractionModelMetadata Metadata for text extraction models
#' @param etag Used to perform a consistent read-modify-write updates
#' @param createTime Output only
#' @param updateTime Output only
#' @param imageClassificationModelMetadata Metadata for image classification models
#' @param displayName Required
#' 
#' @return Model object
#' 
#' @family Model functions
#' @export
Model <- function(Model.labels = NULL, imageObjectDetectionModelMetadata = NULL, 
    deploymentState = NULL, datasetId = NULL, labels = NULL, textSentimentModelMetadata = NULL, 
    translationModelMetadata = NULL, name = NULL, textClassificationModelMetadata = NULL, 
    textExtractionModelMetadata = NULL, etag = NULL, createTime = NULL, updateTime = NULL, 
    imageClassificationModelMetadata = NULL, displayName = NULL) {
    structure(list(Model.labels = Model.labels, imageObjectDetectionModelMetadata = imageObjectDetectionModelMetadata, 
        deploymentState = deploymentState, datasetId = datasetId, labels = labels, 
        textSentimentModelMetadata = textSentimentModelMetadata, translationModelMetadata = translationModelMetadata, 
        name = name, textClassificationModelMetadata = textClassificationModelMetadata, 
        textExtractionModelMetadata = textExtractionModelMetadata, etag = etag, createTime = createTime, 
        updateTime = updateTime, imageClassificationModelMetadata = imageClassificationModelMetadata, 
        displayName = displayName), class = "gar_Model")
}

#' Model.labels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional. The labels with user-defined metadata to organize your model. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter. See https://goo.gl/xmQnxf for more information on and examples of labels.
#' 
#' 
#' 
#' @return Model.labels object
#' 
#' @family Model functions
#' @export
Model.labels <- function() {
    list()
}

#' Dataset Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A workspace for solving a single, particular machine learning (ML) problem. A workspace contains examples that may be annotated.
#' 
#' @param Dataset.labels The \link{Dataset.labels} object or list of objects
#' @param imageObjectDetectionDatasetMetadata Metadata for a dataset used for image object detection
#' @param labels Optional
#' @param displayName Required
#' @param textClassificationDatasetMetadata Metadata for a dataset used for text classification
#' @param name Output only
#' @param textExtractionDatasetMetadata Metadata for a dataset used for text extraction
#' @param etag Used to perform consistent read-modify-write updates
#' @param translationDatasetMetadata Metadata for a dataset used for translation
#' @param textSentimentDatasetMetadata Metadata for a dataset used for text sentiment
#' @param exampleCount Output only
#' @param imageClassificationDatasetMetadata Metadata for a dataset used for image classification
#' @param description User-provided description of the dataset
#' @param createTime Output only
#' 
#' @return Dataset object
#' 
#' @family Dataset functions
#' @export
Dataset <- function(Dataset.labels = NULL, imageObjectDetectionDatasetMetadata = NULL, 
    labels = NULL, displayName = NULL, textClassificationDatasetMetadata = NULL, 
    name = NULL, textExtractionDatasetMetadata = NULL, etag = NULL, translationDatasetMetadata = NULL, 
    textSentimentDatasetMetadata = NULL, exampleCount = NULL, imageClassificationDatasetMetadata = NULL, 
    description = NULL, createTime = NULL) {
    structure(list(Dataset.labels = Dataset.labels, imageObjectDetectionDatasetMetadata = imageObjectDetectionDatasetMetadata, 
        labels = labels, displayName = displayName, textClassificationDatasetMetadata = textClassificationDatasetMetadata, 
        name = name, textExtractionDatasetMetadata = textExtractionDatasetMetadata, 
        etag = etag, translationDatasetMetadata = translationDatasetMetadata, textSentimentDatasetMetadata = textSentimentDatasetMetadata, 
        exampleCount = exampleCount, imageClassificationDatasetMetadata = imageClassificationDatasetMetadata, 
        description = description, createTime = createTime), class = "gar_Dataset")
}

#' Dataset.labels Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' Optional. The labels with user-defined metadata to organize your dataset. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter. See https://goo.gl/xmQnxf for more information on and examples of labels.
#' 
#' 
#' 
#' @return Dataset.labels object
#' 
#' @family Dataset functions
#' @export
Dataset.labels <- function() {
    list()
}


#' AnnotationSpec Object
#' 
#' @details 
#' Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
#' A definition of an annotation spec.
#' 
#' @param name Output only
#' @param exampleCount Output only
#' @param displayName Required
#' 
#' @return AnnotationSpec object
#' 
#' @family AnnotationSpec functions
#' @export


AnnotationSpec <- function(name = NULL, exampleCount = NULL, displayName = NULL) {
    
    
    
    structure(list(name = name, exampleCount = exampleCount, displayName = displayName), 
        class = "gar_AnnotationSpec")
}

