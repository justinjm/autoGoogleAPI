% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/automl_objects.R
\name{OutputConfig}
\alias{OutputConfig}
\title{OutputConfig Object}
\usage{
OutputConfig(gcsDestination = NULL)
}
\arguments{
\item{gcsDestination}{Required}
}
\value{
OutputConfig object
}
\description{
OutputConfig Object
}
\details{
Autogenerated via \code{\link[googleAuthR]{gar_create_api_objects}}
*  For Translation:        CSV file `translation.csv`, with each line in format:        ML_USE,GCS_FILE_PATH        GCS_FILE_PATH leads to a .TSV file which describes examples that have        given ML_USE, using the following row format per line:        TEXT_SNIPPET (in source language) \t TEXT_SNIPPET (in target        language)  *  For Tables:        Output depends on whether the dataset was imported from Google Cloud        Storage or BigQuery.        Google Cloud Storage case:gcs_destination          must be set. Exported are CSV file(s) `tables_1.csv`,          `tables_2.csv`,...,`tables_N.csv` with each having as header line          the table's column names, and all other lines contain values for          the header columns.        BigQuery case:bigquery_destination          pointing to a BigQuery project must be set. In the given project a          new dataset will be created with name`export_data_<automl-dataset-display-name>_<timestamp-of-export-call>`          where <automl-dataset-display-name> will be made          BigQuery-dataset-name compatible (e.g. most special characters will          become underscores), and timestamp will be in          YYYY_MM_DDThh_mm_ss_sssZ 'based on ISO-8601' format. In that          dataset a new table called `primary_table` will be created, and          filled with precisely the same data as this obtained on import.
}
\concept{OutputConfig functions}
